{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5cce0d-5e59-4874-8551-e9be2907a242",
   "metadata": {
    "id": "eb5cce0d-5e59-4874-8551-e9be2907a242"
   },
   "source": [
    "# **Chapter 1 머신러닝과 딥러닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee0955-5d1c-4937-a806-99345cdb9f30",
   "metadata": {
    "id": "efee0955-5d1c-4937-a806-99345cdb9f30"
   },
   "source": [
    "# **Chapter 2 실습 환경 설정과 파이토치 기초**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692644c1-0b59-4608-b32a-35bb55a0e4f1",
   "metadata": {
    "id": "692644c1-0b59-4608-b32a-35bb55a0e4f1"
   },
   "source": [
    "### **[개념 정리]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df920ab-3b60-4168-a7ef-e69914f6ab26",
   "metadata": {
    "id": "6df920ab-3b60-4168-a7ef-e69914f6ab26"
   },
   "source": [
    "#### **1.1 인공지능, 머신러닝과 딥러닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c3b01-f27b-44d7-9d37-f3013f92f000",
   "metadata": {
    "id": "8c6c3b01-f27b-44d7-9d37-f3013f92f000"
   },
   "source": [
    "인공지능(Artificial Intelligence, AI)\n",
    "> 인간의 지능을 모방하여 사람이 하는 일을 기계가 할 수 있도록 하는 기술\n",
    "> 인공지능과 머신러닝, 딥러닝의 관계\n",
    "\n",
    "머신러닝\n",
    "> 주어진 데이터를 인간이 먼저 전처리 해주어야 함.\n",
    "> 만약 이미지 데이터라면 사람이 학습 데이터를 컴퓨터가 인식할 수 있도록 준비해 두어야 하는 것\n",
    "> - 따라서, 머신러닝은 범용적 목적을 위해 제작된 것으로 데이터의 특징을 스스로 추출하지 못함.\n",
    "- 머신러닝의 학습 과정\n",
    "  > 각 데이터 특성을 기계에 인식시키고 학습시켜 문제를 해결\n",
    "\n",
    "딥러닝\n",
    "> 인간이 하던 작업(머신러닝에서 언급한 부분)을 생략\n",
    "> 대량의 데이터를 신경망에 적용하면 컴퓨터가 스스로 분석한 후 답을 찾음\n",
    "\n",
    "머신러닝과 딥러닝의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea9ff8-6c7e-4224-9cbe-21f5c954961d",
   "metadata": {
    "id": "2aea9ff8-6c7e-4224-9cbe-21f5c954961d"
   },
   "source": [
    "#### **1.2 머신러닝이란**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9387a-aba6-4d53-911f-59b54eee5109",
   "metadata": {
    "id": "34c9387a-aba6-4d53-911f-59b54eee5109"
   },
   "source": [
    "머신러닝\n",
    "> 인공지능의 한 분야로, 컴퓨터 스스로 대용량 데이터에서 지식이나 패턴을 찾아 학습하고 예측을 수행하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71533914-d79e-416b-8d97-4ea027e116a9",
   "metadata": {
    "id": "71533914-d79e-416b-8d97-4ea027e116a9"
   },
   "source": [
    "##### **1.2.1 머신러닝 학습 과정**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40a8c3-5475-43b4-a45e-05cf6ced5988",
   "metadata": {
    "id": "4a40a8c3-5475-43b4-a45e-05cf6ced5988"
   },
   "source": [
    "머신러닝의 주요 구성 요소\n",
    "\n",
    "1. 데이터\n",
    "> 머신러닝이 학습 모델을 만드는 데 사용한느 것\n",
    "> 실제 데이터의 특징이 잘 반영되고, 편향되지 않는 훈련 데이터를 확보하는 것이 중요\n",
    "> - 학습에 필요한 데이터가 수집되었다면, '훈련 데이터셋'과 '테스트 데이터셋'으로 분리하여 사용\n",
    "\n",
    "2. 모델(모형)\n",
    "> 머신러닝의 학습 단계에서 얻은 최종 결과물\n",
    "> - 모델의 학습 절차\n",
    ">   1. 모델 선택\n",
    ">   2. 모델 학습 및 평가\n",
    ">   3. 평가를 바탕으로 모델 업데이트\n",
    "> - 훈련과 검증, 테스트 데이터셋\n",
    "> - 모델 성능 평가가 필요한 이유\n",
    ">   1. 테스트 데이터셋에 대한 성능을 가늠해볼 수 있음\n",
    ">   2. 모델 성능을 높이는 데에 도움\n",
    ">      - 만약, 훈련 데이터셋에 대한 정확도는 높은데, 검증 데이터셋에 대한 정확도가 낮다면 훈련 데이터셋에 과적합이 일어났을 가능성 존재 -> 정규화를 하거나 에포크를 줄이는 방식으로 과적합 방지 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080e85f-69e7-40d8-b842-04c646dcf39e",
   "metadata": {
    "id": "8080e85f-69e7-40d8-b842-04c646dcf39e"
   },
   "source": [
    "##### **1.2.2 머신러닝 학습 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9adda-a8b8-4451-86ad-269c7f379b9b",
   "metadata": {
    "id": "d4a9adda-a8b8-4451-86ad-269c7f379b9b"
   },
   "source": [
    "1. 지도 학습\n",
    "> 정답이 무엇인지 컴퓨터에 알려주고 학습시키는 방법\n",
    "\n",
    "2. 비지도 학습\n",
    "> 정답을 알려주지 않고, 특징이 비슷한 데이터를 클러스터링하여 예측하는 학습 방법\n",
    "\n",
    "3. 강화 학습\n",
    "> 자신의 행동에 대한 보상을 받으며 학습을 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f524c61-4095-4681-8a8c-d91d3da86b75",
   "metadata": {
    "id": "5f524c61-4095-4681-8a8c-d91d3da86b75"
   },
   "source": [
    "#### **1.3 딥러닝이란**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbc352-e617-447c-adf0-2cbb06a0002e",
   "metadata": {
    "id": "0dbbc352-e617-447c-adf0-2cbb06a0002e"
   },
   "source": [
    "딥러닝\n",
    "> 인간의 신경망 원리를 모방한 심층 신경망 이론을 기반으로 고안된 머신러닝 방법의 일종\n",
    "> 머신러닝과의 차이점은 인간의 뇌를 기초로 하여 설계했다는 점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245960d-3947-4a82-a74f-9402c7520153",
   "metadata": {
    "id": "e245960d-3947-4a82-a74f-9402c7520153"
   },
   "source": [
    "##### **1.3.1 딥러닝 학습 과정**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ce775-7e4b-43ee-ac0c-5da8d1553251",
   "metadata": {
    "id": "827ce775-7e4b-43ee-ac0c-5da8d1553251"
   },
   "source": [
    "1. 데이터 준비\n",
    "\n",
    "2. 모델 정의\n",
    "> 일반적으로 은닉층 개수가 많을수록 성능이 좋아히지만, 과적합 발생 확률이 높음\n",
    "\n",
    "3. 모델 컴파일\n",
    "> 활성화 함수, 손실 함수, 옵티마이저 선택 (과적합을 피하는 것이 중요)\n",
    "\n",
    "4. 모델 훈련\n",
    "> 에포크 선택의 중요성\n",
    "> - 한 번에 처리해야 할 데이터양이 많아지면 학습 속도가 느려지고 메모리가 부족해지는 문제를 야기하기 때문에, 적당한 데이터 묶음을 선택하는 것이 중요\n",
    "> 배치 크기 선택\n",
    "> - '훈련 데이터셋 1000개에 대한 배치 크기가 20'이라면 샘플 단위 20개마다 모델 가중치를 한 번씩 업데이트\n",
    "> - 즉, 총 50번의 가중치가 업데이트\n",
    "> - 여기서 에포크가 10이면 가중치를 50번 업데이트하는 것을 총 10번 반복한다는 의미\n",
    "> - 결과적으로, 가중치가 총 500번 업데이트\n",
    "\n",
    "5. 모델 예측\n",
    "> 성능이 좋다는 의미?\n",
    "> - 궁극적으로 모델 성능은 데이터가 수집된 산업 분야와 모델이 생성된 목적에 의존한다고 볼 수있음\n",
    "\n",
    "딥러닝에서 중요한 핵심 구성 요소\n",
    "\n",
    "1. 신경망\n",
    "> 심층 신경망\n",
    "> - 데이터셋의 어떤 특성들이 중요한 지 스스로에게 가르쳐 줄 수 있는 기능 탑재\n",
    "\n",
    "2. 역전파\n",
    "> 가중치 값을 업데이트하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b1ced-b245-4ce8-a710-e1d3804ea0ee",
   "metadata": {
    "id": "236b1ced-b245-4ce8-a710-e1d3804ea0ee"
   },
   "source": [
    "##### **1.3.2 딥러닝 학습 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817493a-712e-4b95-9ab5-a3ff06254901",
   "metadata": {
    "id": "a817493a-712e-4b95-9ab5-a3ff06254901"
   },
   "source": [
    "1. 지도 학습\n",
    "> 이미지 분류\n",
    "> - 이미지 또는 비디오상의 객체를 식별하는 컴퓨터 비전 기술\n",
    "> - 컴퓨터 비전에서 가장 많이 사용되는 것이 합성곱 신경망(CNN)\n",
    "\n",
    "- 합성곱 신경망\n",
    "  1. 이미지 분류\n",
    "  > 이미지를 알고리즘에 입력하면 그 이미지가 어떤 클래스에 속하는지 알려줌 -> 이미지 데이터를 유사한 것끼리 분류할 때 사용\n",
    "  \n",
    "  2. 이미지 인식\n",
    "  > 사진을 분석하여 그 안에 있는 사물의 종류를 인식하는 것\n",
    "\n",
    "  3. 이미지 분할\n",
    "  > 영상에서 사물이나 배경 등 객체 간 영역을 픽셀 단위로 구분하는 기술\n",
    "\n",
    "> 시계열 데이터를 분류할 때 사용되는 것이 순환 신경망(RNN)\n",
    "> - 역전파 과정에서 기울기가 소멸하는 문제가 발생하는 단점으로, 게이트(Gate)를 3개 추가한 LSTM 사용\n",
    "\n",
    "2. 비지도 학습\n",
    "> 1. 워드 임베팅\n",
    "> - 자연어를 컴퓨터가 이해하고 효율적으로 처리하게 하려면 컴퓨터가 이해할 수 있도록 자연어를 적절히 변환하는 과정 (단어)\n",
    "> - 단어 의미를 벡터화하는 워드투벡터(Word2Vec), 글로브(Glove) 사용\n",
    "> 2. 군집\n",
    "> - 아무런 정보가 없는 상태에서 데이터를 분류하는 방법\n",
    "> - 머신러닝의 군집과 다르지 않음. 하지만, 머신러닝에서 군집화를 처리할 때 딥러닝과 함께 사용하면 모델 성능을 높일 수 있어 머신러닝 단독으로 군집 알고리즘을 적용하기보단 딥러닝과 함께 사용하는 것이 좋음.\n",
    "\n",
    "3. 전이 학습\n",
    "> 사전에 학습이 완료된 모델(사전 학습 모델)을 가지고 우리가 원하는 학습에 미세 조정 기법을 이용하여 학습시키는 방법\n",
    "> 사전 학습 모델\n",
    "> - 풀고자 하는 문제와 비슷하면서 많은 데이터로 이미 학습이 되어 있는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32253daa-fb4c-4c0b-a154-fe683ac2a8b3",
   "metadata": {
    "id": "32253daa-fb4c-4c0b-a154-fe683ac2a8b3"
   },
   "source": [
    "#### **2.1 파이토치 개요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c346ef0-2be5-4e1e-9d0a-67c4574fe18a",
   "metadata": {
    "id": "2c346ef0-2be5-4e1e-9d0a-67c4574fe18a"
   },
   "source": [
    "파이토치(PyTorch)\n",
    "> 1. 넘파이를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
    "> 2. 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42499d58-eff3-457c-918b-7b1f0022506b",
   "metadata": {
    "id": "42499d58-eff3-457c-918b-7b1f0022506b"
   },
   "source": [
    "##### **2.1.1 파이토치 특징 및 장점**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1d690-66ef-4319-89dc-77b13b3b5889",
   "metadata": {
    "id": "1de1d690-66ef-4319-89dc-77b13b3b5889"
   },
   "source": [
    "GPU에서 텐서 조작 및 동적 신경망 구축이 가능한 프레임워크\n",
    "\n",
    "- GPU: 연산 속도를 빠르게 하는 역할\n",
    "- 텐서(Tensor): 파이토치의 데이터 형태, 단일 데이터 형식으로 된 자료들의 다차원 행렬\n",
    "- 동적 신경망: 훈련을 반복할 때마다 네트워크 변경이 가능한 신경망\n",
    "\n",
    "인공지능에서 데이터는 벡터로 표현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8458310-a159-453f-96bd-12d91a6e0a61",
   "metadata": {
    "id": "c8458310-a159-453f-96bd-12d91a6e0a61"
   },
   "source": [
    "##### **2.1.2 파이토치의 아키텍처**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141aedda-cb45-4092-b5ba-732ac3804a18",
   "metadata": {
    "id": "141aedda-cb45-4092-b5ba-732ac3804a18"
   },
   "source": [
    "파이토치 API\n",
    "- torch: GPU를 지원하는 텐서 패키지\n",
    "- torch.autograd: 자동 미분 패키지\n",
    "- torch.nn: 신경망 구축 및 훈련 패키지\n",
    "- torch.multiprocessing: 파이씬 멀티프로세싱 패키지\n",
    "- torch.utils: DataLoader 및 기타 유틸리티를 제공하는 패키지\n",
    "\n",
    "파이토치 엔진\n",
    "\n",
    "연산 처리\n",
    "- 가장 아래 계층에 속하는 C 또는 CUDA 패키지는 상위의 API에서 할당된 거의 모든 계산을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14909df6-02d3-4026-9455-3390453940af",
   "metadata": {
    "id": "14909df6-02d3-4026-9455-3390453940af"
   },
   "source": [
    "#### **2.2 파이토치 기초 문법**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4siYmcrYKzeZ",
   "metadata": {
    "id": "4siYmcrYKzeZ"
   },
   "source": [
    "#### **2.2.3 모델 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T2CaLZCPK2TW",
   "metadata": {
    "id": "T2CaLZCPK2TW"
   },
   "source": [
    "- 계층(layer)\n",
    "> 모듈 또는 모듈을 구성하는 1개의 계층으로 합성곱층(convolutional layer), 선형계층(linear layer) 등\n",
    "\n",
    "- 모듈(module)\n",
    "> 1개 이상의 계층이 모여서 구성된 것\n",
    "\n",
    "- 모델(model)\n",
    "> 최종적으로 원하는 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b57a2-8bad-4e95-818e-c4959f3074dd",
   "metadata": {
    "id": "cd0b57a2-8bad-4e95-818e-c4959f3074dd"
   },
   "source": [
    "### **[필사]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebcc7f-2931-47e8-aee8-490c8ba03255",
   "metadata": {
    "id": "a9ebcc7f-2931-47e8-aee8-490c8ba03255"
   },
   "source": [
    "#### **2.1 파이토치 개요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c658dbc-273d-4326-b537-ca48fd8b4ceb",
   "metadata": {
    "id": "4c658dbc-273d-4326-b537-ca48fd8b4ceb"
   },
   "source": [
    "##### **2.1.1 파이토치 특징 및 장점**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0970c5c-97ab-493d-96e8-18012f30376b",
   "metadata": {
    "id": "c0970c5c-97ab-493d-96e8-18012f30376b",
    "outputId": "489be0b8-7921-4ca7-8ecc-752eb6c5e7f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([[1., -1.], [1., -1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cbef9-a488-44d7-b247-6c4bf7de0c9d",
   "metadata": {
    "id": "026cbef9-a488-44d7-b247-6c4bf7de0c9d"
   },
   "source": [
    "##### **2.2.1 텐서 다루기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565fccd-8400-411a-bb61-9538bd9d6193",
   "metadata": {
    "id": "f565fccd-8400-411a-bb61-9538bd9d6193"
   },
   "source": [
    "텐서 생성 및 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd3aa0b-db7d-433c-9975-a0854b0c8db0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cd3aa0b-db7d-433c-9975-a0854b0c8db0",
    "outputId": "70b28519-bd26-4ca2-eb6d-c94cab06504a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([[1, 2], [3, 4]])) # 2차원 형태의 텐서 생성\n",
    "print(torch.tensor([[1, 2], [3, 4]], device=\"cuda:0\")) # GPU에 텐서 생성\n",
    "print(torch.tensor([[1, 2], [3, 4]], dtype=torch.float64)) # dtype을 이용하여 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36295840-1844-405c-b47f-f5c3f1dca4c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36295840-1844-405c-b47f-f5c3f1dca4c1",
    "outputId": "cd595c35-34ab-4e37-b2ed-ce155756e3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])\n",
    "print(temp.numpy()) # 텐서를 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcdd5ac-bc61-45db-b680-77e8894504b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dcdd5ac-bc61-45db-b680-77e8894504b6",
    "outputId": "5c6a19b9-c465-4547-9791-2b6e983022bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]], device=\"cuda:0\")\n",
    "print(temp.to(\"cpu\").numpy()) # GPU상의 텐서를 CPU의 텐서로 변환할 후 ndarray로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e827d03-62a8-4b1e-bde0-be5c56b9ce91",
   "metadata": {
    "id": "0e827d03-62a8-4b1e-bde0-be5c56b9ce91"
   },
   "source": [
    "텐서의 인덱스 조작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e456f82-02ad-4eba-a3ca-1bce7791efcf",
   "metadata": {
    "id": "9e456f82-02ad-4eba-a3ca-1bce7791efcf"
   },
   "source": [
    "- torch.FloatTensor: 32비트의 부동 소수점\n",
    "- torch.DoubleTensor: 64비트의 부동 소수점\n",
    "- torch.LongTensor: 64비트의 부호가 있는 정수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83370e44-723c-4e38-be1f-0fa87eb7ebbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83370e44-723c-4e38-be1f-0fa87eb7ebbf",
    "outputId": "2e32f368-e422-4fbb-b730-b4f4f370ea82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "--------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7]) # 파이토치로 1차원 벡터 생성\n",
    "print(temp[0], temp[1], temp[-1]) # 인덱스로 접근\n",
    "print('--------------------------')\n",
    "print(temp[2:5], temp[4:-1]) # 슬라이스로 접근"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518644e-ec8e-4a39-a8fe-38f316ad4eae",
   "metadata": {
    "id": "e518644e-ec8e-4a39-a8fe-38f316ad4eae"
   },
   "source": [
    "텐서 연산 및 차원 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5e48f2-4d99-4b22-88b8-99bdb4350da0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f5e48f2-4d99-4b22-88b8-99bdb4350da0",
    "outputId": "e523fe95-b801-4155-8b97-1a0eafa948b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v) # 길이가 같은 벡터 간 뺄셈 연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f005e00-b875-4ec2-898a-431e56fa363a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f005e00-b875-4ec2-898a-431e56fa363a",
    "outputId": "f0eabfa0-fd8d-4397-93dc-3cdba5b13772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "-----------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "-----------------------------\n",
      "tensor([1, 2, 3, 4])\n",
      "-----------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "-----------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('-----------------------------')\n",
    "print(temp.view(4, 1))\n",
    "print('-----------------------------')\n",
    "print(temp.view(-1))\n",
    "print('-----------------------------')\n",
    "print(temp.view(1, -1))\n",
    "print('-----------------------------')\n",
    "print(temp.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73vIKuc8HNyN",
   "metadata": {
    "id": "73vIKuc8HNyN"
   },
   "source": [
    "#### **2.2.2 데이터 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35elXjzzHQ2k",
   "metadata": {
    "id": "35elXjzzHQ2k"
   },
   "source": [
    "단순하게 파일을 불러와서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5xSIQuLIHVQh",
   "metadata": {
    "id": "5xSIQuLIHVQh"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# data = pd.read_csv('../class2.csv')\n",
    "\n",
    "# x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "# y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fRr0IFpFHtJx",
   "metadata": {
    "id": "fRr0IFpFHtJx"
   },
   "source": [
    "커스텀 데이터셋을 만들어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lR9JDamGHvR9",
   "metadata": {
    "id": "lR9JDamGHvR9"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#   def __init__(self, csv_file):\n",
    "#     self.label = pd.read_csv(csv_file)\n",
    "\n",
    "#   def __len__(self):\n",
    "#     return len(self.label)\n",
    "\n",
    "#   def __getitem__(self, idx):\n",
    "#     sample = torch.tensor(self.label.iloc[idx, 0:3]).int()\n",
    "#     label = torch.tensor(self.label.iloc[idx, 3]).int()\n",
    "#     return sample, label\n",
    "\n",
    "# tensor_dataset = CustomDataset('../covtype.csv')\n",
    "# dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NNX0EvTFIX7k",
   "metadata": {
    "id": "NNX0EvTFIX7k"
   },
   "outputs": [],
   "source": [
    "# for i data in enumerate(dataset, 0):\n",
    "#   print(i, end='')\n",
    "#   batch=data[0]\n",
    "#   print(batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1mUmkPbMJ6-5",
   "metadata": {
    "id": "1mUmkPbMJ6-5"
   },
   "source": [
    "파이토치에서 제공하는 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "BfX78_QdJ8Yp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfX78_QdJ8Yp",
    "outputId": "10ddfc5b-4d64-4534-9e87-6b2a8639bb3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lR-2U35YKA4g",
   "metadata": {
    "id": "lR-2U35YKA4g"
   },
   "outputs": [],
   "source": [
    "# import torchvision.transform as transforms\n",
    "\n",
    "# mnist_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (1.0,))\n",
    "# ])\n",
    "\n",
    "# from torchivision.datasets import MNIST\n",
    "# import requests\n",
    "\n",
    "# train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "# valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "# test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KVMLndErKtQ0",
   "metadata": {
    "id": "KVMLndErKtQ0"
   },
   "source": [
    "#### **2.2.3 모델 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJvol4X0Kvhb",
   "metadata": {
    "id": "MJvol4X0Kvhb"
   },
   "source": [
    "단순 신경망을 정의하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "PmIEL7BaLLmq",
   "metadata": {
    "id": "PmIEL7BaLLmq"
   },
   "outputs": [],
   "source": [
    "# model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aVkS2spkLRa2",
   "metadata": {
    "id": "aVkS2spkLRa2"
   },
   "source": [
    "nn.Module()을 상속하여 정의 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "-ape8EQ-LVH_",
   "metadata": {
    "id": "-ape8EQ-LVH_"
   },
   "outputs": [],
   "source": [
    "# class MLP(Module):\n",
    "#   def __init__(self, inputs):\n",
    "#     super(MLP, self).__init__()\n",
    "#     self.layer = Linear(inputs, 1)\n",
    "#     self.activation = Sigmoid()\n",
    "\n",
    "#   def forward(self, X):\n",
    "#     X = self.layer(X)\n",
    "#     X = self.activation(X)\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7kA3itTANGvG",
   "metadata": {
    "id": "7kA3itTANGvG"
   },
   "source": [
    "Sequential 신경망을 정의하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Rjwzf5NgNLpF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rjwzf5NgNLpF",
    "outputId": "727b33f8-1ee4-4aee-a194-95b4e10258b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing children\n",
      "------------------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "\n",
      "\n",
      "Printing Modules\n",
      "------------------------------\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2)\n",
    "\n",
    "    )\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2)\n",
    "\n",
    "    )\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.layer1(x)\n",
    "      x = self.layer2(x)\n",
    "      x = x.view(x.shape[0], -1)\n",
    "      x = self.layer3(x)\n",
    "      return x\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "print (\"Printing children\\n------------------------------\")\n",
    "print(list(model .children()))\n",
    "print (\"\\n\\nPrinting Modules\\n------------------------------\")\n",
    "print(list(model .modules()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6gloygXNTeY",
   "metadata": {
    "id": "e6gloygXNTeY"
   },
   "source": [
    "nn.Sequential은 모델의 계층이 복잡할수록 효과가 뛰어남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rvFg5xzINTbd",
   "metadata": {
    "id": "rvFg5xzINTbd"
   },
   "source": [
    "함수로 신경망을 정의하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "AyeDjMM3PPYO",
   "metadata": {
    "id": "AyeDjMM3PPYO"
   },
   "outputs": [],
   "source": [
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "  hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "  activation = nn.ReLU()\n",
    "  output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "  net = nn.Sequential(hidden, activation, output)\n",
    "  return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pXQon0yqPlpV",
   "metadata": {
    "id": "pXQon0yqPlpV"
   },
   "source": [
    "##### **2.2.4 모델의 파라미터 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cqcOkW6ePpe7",
   "metadata": {
    "id": "cqcOkW6ePpe7"
   },
   "outputs": [],
   "source": [
    "# from torch.optim import optimizer\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "\n",
    "# for epoch in range(1, 100+1):\n",
    "#   for x, y in dataloader:\n",
    "#     optimizer.zero_grad()\n",
    "# loss_fn(model(x), y).backward()\n",
    "# optimizer.step()\n",
    "# scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3knpsMw_QH6l",
   "metadata": {
    "id": "3knpsMw_QH6l"
   },
   "source": [
    "##### **2.2.5 모델 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "qS_AxR-7QRc8",
   "metadata": {
    "id": "qS_AxR-7QRc8"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(100):\n",
    "#   yhat = model(x_train)\n",
    "#   loss = criterion(x_train)\n",
    "#   optimizer.zero_grad()\n",
    "#   loss.backward()\n",
    "#   optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i2y4u2iEQbIA",
   "metadata": {
    "id": "i2y4u2iEQbIA"
   },
   "source": [
    "##### **2.2.6 모델 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "nxbw4TKZQeVy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxbw4TKZQeVy",
    "outputId": "c156ca35-f058-4154-db7e-67070e5fcfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "gqp8ddr-Qg3f",
   "metadata": {
    "id": "gqp8ddr-Qg3f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10, ))\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(preds, target, task=\"multiclass\", num_classes=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
